### О курсе
Курс посвящен изучению основ байесовских методов машинного обучения, построения байесовских моделей данных и вывода в них. Рассматриваются оптимальные байесовские прогнозы, а также методы их построения. Освещаются способы учета нелинейностей и неоднородностей в данных, пропусков в данных, а также эволюции оптимальной модели во времени.

### Темы
* Введение: Напоминание понятий из теории вероятностей и статистики.
* Множественное тестирование гипотез и выбор априорного распределения.
* Наивный байесовский классификатор, его обобщения и оптимальный прогноз. Экспоненциальное семейство распределений.
* Байесовская линейная регрессия. Обоснованность (evidence).
* Байесовская логистическая регрессия и отбор признаков.
* EM-алгоритм и вариационный EM-алгоритм.
* Гауссовские процессы и эволюция моделей во времени.
* Построение адекватных мультимоделей.
* Методы Монте-Карло по схеме марковских цепей.
* Гамильтоновы методы Монте-Карло по схеме марковских цепей.
* Байесовская оптимизация.

### Самостоятельная работа
4 теоретических задания (выполняются индивидуально), 1 практическое задание и 1 соревнование (выполняются по командам), 2 теста.
Письменный и устный экзамен (последний можно заменить докладом на тему по выбору).

### Оценивание 
Каждое теоретическое задание дает максимум 50 или 100 баллов, практическое и соревнование — до 150. Баллы автора лучшей работы удваиваются (дополнительные баллы).
Устный и письменный экзамен добавляют до 250 баллов.
Общая оценка рассчитывается шкалированием к максимально возможной без учета дополнительных баллов.

### Требуемые знания
Знание теории вероятностей, основ машинного обучения, линейной алгебры и методов оптимизации.
